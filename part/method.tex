\section{Method}

\subsection{Dilated convolution neural network}
Despite their performance, state-of-the-art models are complex. C-CNN is a bargain trade performance for efficiency. However, there is still room for improvement, while its light-weight characteristic is reserved. 

Dilated CNN have been proven to conserved spatial context information \cite{li2018csrnet}. Inspired by its successed in CSRNet \cite{li2018csrnet} and CAN \cite{liu2019context}, we replace layer all tradition CNN on second layer with Dilated CNN at dilated rate 2. We apply batch normalization \cite{ioffe2015batch} with trainable parameters on each layer, including first multi-scale layers. Follow authors work, we add batch normalization before the nonlinearity, in our case, ReLU \cite{agarap2018deep}. 

% \begin{table}[htbp]
% \caption{Experiment result}





\subsection{Implementation detail}

\subsubsection{Ground-truth generation} \hfill

For ShanghaiTech Part B dataset, we apply Gaussian kernel, original proposed by Lempitsky, \cite{lempitsky2010learning} with $\sigma = 15$ and truncate Gaussian spread at 3 standard deviations. More specific, for each image $I_i$, we define ground truth density function as: 

\begin{equation} \label{eq:densit-function}
\forall p \in I_{i}, \quad F_{i}^{0}(p)=\sum_{P \in \mathbf{P}_{i}} \mathcal{N}\left(p ; P, \sigma^{2} \mathbf{1}_{2 \times 2}\right) 
\end{equation}

Where: 





